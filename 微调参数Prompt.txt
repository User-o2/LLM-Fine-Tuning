## 背景
我正在基于LLama-Factory框架微调qwen3-0.6b大模型。采用LoRA方法进行SFT，数据集的格式为sharegpt格式，大小为3000多次的多轮对话。

## 设备：
GPU：笔记本-RTX4060  8GB显存
CPU：AMD R9-7940H 8核心 - 16线程

## 问题
请你基于以上信息，整理一下，给出以下微调参数设置的最佳实践：

### 一般参数设置
1. 学习率
2. 训练轮数：需要执行的训练总轮数。
3. 最大梯度范数：用于梯度裁剪的范数。
4. 最大样本数：每个数据集的最大样本数。
5. 计算类型：是否使用混合精度训练。
6. 截断长度：可选0-131072，输入序列分词后的最大长度。
7. 批处理大小：每个 GPU 处理的样本数量。
8. 梯度累积：梯度累积的步数。
9. 验证集比例：验证集占全部样本的百分比。
10. 学习率调节器：学习率调度器的名称。
11. 日志间隔：每两次日志输出间的更新步数。
12. 保存间隔：每两次断点保存间的更新步数。
13. 预热步数：学习率预热采用的步数。
14. NEFTune 噪声参数：嵌入向量所添加的噪声大小。
15. 是否启用：序列打包；是否启用：无污染打包。
16. 是否启用：学习提示词[不在提示词的部分添加掩码（仅适用于 SFT）]。
17. 是否启用：不学习历史对话[仅学习最后一轮对话（仅适用于 SFT）]。

### 部分参数微调设置
18. 可训练层数
19. 可训练模块

### LoRA参数设置
20. LoRA秩
21. LoRA缩放系数
22. LoRA随机丢弃概率
23. LoRA+学习率比率
24. 是否启用：新建适配器（在现有的适配器上创建一个随机初始化后的新适配器。）
25. LoRA 作用模块（非必填，应用 LoRA 的模块名称。使用英文逗号分隔多个名称）。